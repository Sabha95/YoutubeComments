{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sabha95/YoutubeComments/blob/Colab-version/Pull_all_Comments_and_Replies_for_YouTube_Playlists.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "jF_ENh3atCvf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "import pandas as pd\n",
        "from google.colab import files, drive\n",
        "import getpass\n",
        "from textblob import TextBlob\n",
        "import numpy as np\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "I3JYDedSB02s"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## User Input"
      ],
      "metadata": {
        "id": "svxnefn2B5Yt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = getpass.getpass('Please enter your YouTube API key: ')\n",
        "\n"
      ],
      "metadata": {
        "id": "shzPziGAsy_l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c86da113-0258-4359-975c-9cd193fdc1e3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please enter your YouTube API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "hK5fMz-Zgg_F"
      },
      "outputs": [],
      "source": [
        "# Build the YouTube client\n",
        "youtube = build('youtube', 'v3', developerKey=api_key)\n",
        "playlist_ids = ['PLbHrOSG7nVN0iy3JQonGt6p6illtDhoqX']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Video IDs for Playlist"
      ],
      "metadata": {
        "id": "EGeNx0lTCUNL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_all_video_ids_from_playlists(youtube, playlist_ids):\n",
        "    all_videos = []  # Initialize a single list to hold all video IDs\n",
        "\n",
        "    for playlist_id in playlist_ids:\n",
        "        next_page_token = None\n",
        "\n",
        "        # Fetch videos from the current playlist\n",
        "        while True:\n",
        "            playlist_request = youtube.playlistItems().list(\n",
        "                part='contentDetails',\n",
        "                playlistId=playlist_id,\n",
        "                maxResults=50,\n",
        "                pageToken=next_page_token)\n",
        "            playlist_response = playlist_request.execute()\n",
        "\n",
        "            all_videos += [item['contentDetails']['videoId'] for item in playlist_response['items']]\n",
        "\n",
        "            next_page_token = playlist_response.get('nextPageToken')\n",
        "\n",
        "            if next_page_token is None:\n",
        "                break\n",
        "\n",
        "    return all_videos\n",
        "\n",
        "# Fetch all video IDs from the specified playlists\n",
        "video_ids = get_all_video_ids_from_playlists(youtube, playlist_ids)\n",
        "\n",
        "# Now you can pass video_ids to the next function\n",
        "# next_function(video_ids)"
      ],
      "metadata": {
        "id": "zL7LFvM4BO_a"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentimental analysis"
      ],
      "metadata": {
        "id": "cKxWsKu6nESf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class YouTubeMentalHealthAnalyzer:\n",
        "    def __init__(self, api_key):\n",
        "        self.youtube = build('youtube', 'v3', developerKey=api_key)\n",
        "\n",
        "    def get_video_data(self, video_id):\n",
        "        \"\"\"Fetch comprehensive video metadata\"\"\"\n",
        "        try:\n",
        "            request = self.youtube.videos().list(\n",
        "                part='snippet,statistics,contentDetails',\n",
        "                id=video_id\n",
        "            )\n",
        "            response = request.execute()\n",
        "\n",
        "            if not response['items']:\n",
        "                return None\n",
        "\n",
        "            video = response['items'][0]\n",
        "            return {\n",
        "                'video_id': video_id,\n",
        "                'title': video['snippet']['title'],\n",
        "                'description': video['snippet']['description'],\n",
        "                'published_date': video['snippet']['publishedAt'],\n",
        "                'view_count': int(video['statistics'].get('viewCount', 0)),\n",
        "                'like_count': int(video['statistics'].get('likeCount', 0)),\n",
        "                'comment_count': int(video['statistics'].get('commentCount', 0)),\n",
        "                'duration': video['contentDetails']['duration'],\n",
        "                'tags': video['snippet'].get('tags', []),\n",
        "                'category_id': video['snippet']['categoryId']\n",
        "            }\n",
        "        except:\n",
        "           print(\"Error\")\n",
        "\n",
        "\n",
        "    def get_comments_with_sentiment(self, video_id, max_results=100000):\n",
        "        \"\"\"Fetch comments with sentiment analysis\"\"\"\n",
        "        comments_data = []\n",
        "\n",
        "        request = self.youtube.commentThreads().list(\n",
        "            part='snippet,replies',\n",
        "            videoId=video_id,\n",
        "            maxResults=max_results,\n",
        "            textFormat='plainText'\n",
        "        )\n",
        "\n",
        "        while request:\n",
        "            response = request.execute()\n",
        "\n",
        "            for item in response['items']:\n",
        "                comment = item['snippet']['topLevelComment']['snippet']\n",
        "\n",
        "                # Perform sentiment analysis\n",
        "                sentiment = TextBlob(comment['textDisplay']).sentiment\n",
        "\n",
        "                comment_data = {\n",
        "                    'comment_id': item['id'],\n",
        "                    'video_id': video_id,\n",
        "                    'text': comment['textDisplay'],\n",
        "                    'author': comment['authorDisplayName'],\n",
        "                    'published_at': comment['publishedAt'],\n",
        "                    'like_count': comment['likeCount'],\n",
        "                    'reply_count': item['snippet']['totalReplyCount'],\n",
        "                    'is_reply': False,\n",
        "                    'parent_id': None,\n",
        "                    'sentiment_polarity': sentiment.polarity,\n",
        "                    'sentiment_subjectivity': sentiment.subjectivity\n",
        "                }\n",
        "\n",
        "                comments_data.append(comment_data)\n",
        "\n",
        "                # Get replies if they exist\n",
        "                if 'replies' in item:\n",
        "                    for reply in item['replies']['comments']:\n",
        "                        reply_snippet = reply['snippet']\n",
        "                        reply_sentiment = TextBlob(reply_snippet['textDisplay']).sentiment\n",
        "\n",
        "                        reply_data = {\n",
        "                            'comment_id': reply['id'],\n",
        "                            'video_id': video_id,\n",
        "                            'text': reply_snippet['textDisplay'],\n",
        "                            'author': reply_snippet['authorDisplayName'],\n",
        "                            'published_at': reply_snippet['publishedAt'],\n",
        "                            'like_count': reply_snippet['likeCount'],\n",
        "                            'reply_count': 0,\n",
        "                            'is_reply': True,\n",
        "                            'parent_id': item['id'],\n",
        "                            'sentiment_polarity': reply_sentiment.polarity,\n",
        "                            'sentiment_subjectivity': reply_sentiment.subjectivity\n",
        "                        }\n",
        "\n",
        "                        comments_data.append(reply_data)\n",
        "\n",
        "            request = self.youtube.commentThreads().list_next(request, response)\n",
        "\n",
        "        return pd.DataFrame(comments_data)\n",
        "\n",
        "    def analyze_mental_health_indicators(self, text):\n",
        "        \"\"\"Analyze text for mental health-related indicators\"\"\"\n",
        "        # Define keyword dictionaries for different categories\n",
        "        support_seeking = ['help', 'advice', 'struggling', 'need', 'please']\n",
        "        emotional_words = ['anxiety', 'depression', 'stress', 'worried', 'sad']\n",
        "        support_offering = ['hope', 'support', 'here for you', 'understand']\n",
        "\n",
        "        return {\n",
        "            'contains_support_seeking': any(word in text.lower() for word in support_seeking),\n",
        "            'contains_emotional_words': any(word in text.lower() for word in emotional_words),\n",
        "            'contains_support_offering': any(word in text.lower() for word in support_offering)\n",
        "        }\n",
        "\n",
        "    def create_full_dataset(self, video_ids):\n",
        "        \"\"\"Create complete dataset for multiple videos\"\"\"\n",
        "        all_video_data = []\n",
        "        all_comments_data = []\n",
        "\n",
        "        for video_id in video_ids:\n",
        "            # Get video data\n",
        "            video_data = self.get_video_data(video_id)\n",
        "            if video_data:\n",
        "                all_video_data.append(video_data)\n",
        "\n",
        "                # Get comments data\n",
        "                comments_df = self.get_comments_with_sentiment(video_id)\n",
        "\n",
        "                # Add mental health indicators\n",
        "                for idx, row in comments_df.iterrows():\n",
        "                    indicators = self.analyze_mental_health_indicators(row['text'])\n",
        "                    for key, value in indicators.items():\n",
        "                        comments_df.at[idx, key] = value\n",
        "\n",
        "                all_comments_data.append(comments_df)\n",
        "\n",
        "        return pd.DataFrame(all_video_data), pd.concat(all_comments_data, ignore_index=True)\n",
        "\n",
        "# self = YouTubeMentalHealthAnalyzer(api_key)\n",
        "# commentsDF = self.create_full_dataset(video_ids)"
      ],
      "metadata": {
        "id": "WVEunXO1nCB0"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PE46w7Ho0mYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "call the class"
      ],
      "metadata": {
        "id": "utOEoc_xyWz5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_youtube_analysis():\n",
        "    # 1. Initialize the analyzer with your API key\n",
        "\n",
        "    analyzer = YouTubeMentalHealthAnalyzer(api_key)\n",
        "\n",
        "    # 2. Define list of video IDs to analyze\n",
        "    # You can get video IDs from YouTube URLs (the part after v=)\n",
        "\n",
        "\n",
        "    # 3. Create the complete dataset\n",
        "    videos_df, comments_df = analyzer.create_full_dataset(video_ids)\n",
        "\n",
        "    # 4. Save to CSV files\n",
        "    timestamp = pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')\n",
        "    csvFile1=f'youtube_videos_{timestamp}.csv'\n",
        "    csvFile2=f'youtube_comments_{timestamp}.csv'\n",
        "    videos_df.to_csv(csvFile1, index=False)\n",
        "    comments_df.to_csv(csvFile2, index=False)\n",
        "    files.download(csvFile1)\n",
        "    files.download(csvFile2)\n",
        "    # 5. Display some basic statistics\n",
        "    print(\"\\nVideo Dataset Summary:\")\n",
        "    print(f\"Total videos analyzed: {len(videos_df)}\")\n",
        "    print(\"\\nComment Dataset Summary:\")\n",
        "    print(f\"Total comments collected: {len(comments_df)}\")\n",
        "    print(f\"Average sentiment polarity: {comments_df['sentiment_polarity'].mean():.2f}\")\n",
        "\n",
        "    return videos_df, comments_df\n",
        "\n",
        "# Run the analysis\n",
        "if __name__ == \"__main__\":\n",
        "    videos_df, comments_df = run_youtube_analysis()\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "id": "La-EKUTOybiz",
        "outputId": "c119fb62-1a63-43e0-969b-18105cd8f7f0"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_41450092-fce2-4244-9fca-3a09e44e80a3\", \"youtube_videos_20250209_180507.csv\", 7231)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3140abd5-1df2-4ac9-bc64-0b9a8764dc93\", \"youtube_comments_20250209_180507.csv\", 22550)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Video Dataset Summary:\n",
            "Total videos analyzed: 2\n",
            "\n",
            "Comment Dataset Summary:\n",
            "Total comments collected: 92\n",
            "Average sentiment polarity: 0.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get All Comments"
      ],
      "metadata": {
        "id": "dQ-LTgQatXIi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#original function\n",
        "# Function to get replies for a specific comment\n",
        "def get_replies(youtube, parent_id, video_id):  # Added video_id as an argument\n",
        "    replies = []\n",
        "    next_page_token = None\n",
        "\n",
        "    while True:\n",
        "        reply_request = youtube.comments().list(\n",
        "            part=\"snippet\",\n",
        "            parentId=parent_id,\n",
        "            textFormat=\"plainText\",\n",
        "            maxResults=100,\n",
        "            pageToken=next_page_token\n",
        "        )\n",
        "        reply_response = reply_request.execute()\n",
        "\n",
        "        for item in reply_response['items']:\n",
        "            comment = item['snippet']\n",
        "            replies.append({\n",
        "                'Timestamp': comment['publishedAt'],\n",
        "                'Username': comment['authorDisplayName'],\n",
        "                'VideoID': video_id,\n",
        "                'Comment': comment['textDisplay'],\n",
        "                'Date': comment['updatedAt'] if 'updatedAt' in comment else comment['publishedAt']\n",
        "            })\n",
        "\n",
        "        next_page_token = reply_response.get('nextPageToken')\n",
        "        if not next_page_token:\n",
        "            break\n",
        "\n",
        "    return replies\n",
        "\n",
        "# Function to get all comments (including replies) for a single video\n",
        "def get_comments_for_video(youtube, video_id):\n",
        "    all_comments = []\n",
        "    next_page_token = None\n",
        "\n",
        "    while True:\n",
        "        comment_request = youtube.commentThreads().list(\n",
        "            part=\"snippet,replies\",\n",
        "            videoId=video_id,\n",
        "            pageToken=next_page_token,\n",
        "            textFormat=\"plainText\"\n",
        "        )\n",
        "        comment_response = comment_request.execute()\n",
        "\n",
        "        for item in comment_response['items']:\n",
        "            top_comment = item['snippet']['topLevelComment']['snippet']\n",
        "            all_comments.append({\n",
        "                'Timestamp': top_comment['publishedAt'],\n",
        "                'Username': top_comment['authorDisplayName'],\n",
        "                'VideoID': video_id,  # Directly using video_id from function parameter\n",
        "                'Comment': top_comment['textDisplay'],\n",
        "                'Date': top_comment['updatedAt'] if 'updatedAt' in top_comment else top_comment['publishedAt']\n",
        "            })\n",
        "\n",
        "            # Fetch replies if there are any\n",
        "            if item['snippet']['totalReplyCount'] > 0:\n",
        "                all_comments.extend(get_replies(youtube, item['snippet']['topLevelComment']['id'], video_id))\n",
        "\n",
        "        next_page_token = comment_response.get('nextPageToken')\n",
        "        if not next_page_token:\n",
        "            break\n",
        "\n",
        "    return all_comments\n",
        "\n",
        "# List to hold all comments from all videos\n",
        "all_comments = []\n",
        "\n",
        "\n",
        "for video_id in video_ids:\n",
        "    video_comments = get_comments_for_video(youtube, video_id)\n",
        "    all_comments.extend(video_comments)\n",
        "\n",
        "# Create DataFrame\n",
        "comments_df = pd.DataFrame(all_comments)\n"
      ],
      "metadata": {
        "id": "vUdZCrxHmnL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Output to CSV"
      ],
      "metadata": {
        "id": "sQeo2iTwDROo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Export whole dataset to the local machine as CSV File\n",
        "csv_file = 'comments_data.csv'  # Name your file\n",
        "commentsDF.to_csv(csv_file, index=False)\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "# Trigger a download to your local machine\n",
        "files.download(csv_file)"
      ],
      "metadata": {
        "id": "-phDM_447hTR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}